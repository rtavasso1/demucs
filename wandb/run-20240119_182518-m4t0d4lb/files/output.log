torch.float32 torch.float32 torch.float32
0
1
2
0
1
2
step 10000: train loss 0.8683, val loss 1.8975
saving checkpoint to out
iter 10000: loss 0.7661, time 17808.84ms
iter_num:  10001
Traceback (most recent call last):
  File "/home/robertthomas/rileyProject/demucs/new_trainer.py", line 292, in <module>
    pred_onsets, pred_vel = model(audio)
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/accelerate/utils/operations.py", line 687, in forward
    return model_forward(*args, **kwargs)
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/accelerate/utils/operations.py", line 675, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/robertthomas/miniconda3/envs/demucsRiley/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/robertthomas/rileyProject/demucs/demucs/htdemucs.py", line 744, in forward
    x = self._ispec(zout, length)
  File "/home/robertthomas/rileyProject/demucs/demucs/htdemucs.py", line 506, in _ispec
    x = ispectro(z, hl, length=le)
  File "/home/robertthomas/rileyProject/demucs/demucs/spec.py", line 38, in ispectro
    x = th.istft(z,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.75 GiB (GPU 0; 23.65 GiB total capacity; 19.18 GiB already allocated; 1.21 GiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF